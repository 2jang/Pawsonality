"""
OpenRouter API Client
ë‹¤ì–‘í•œ LLM ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” OpenRouter API í´ë¼ì´ì–¸íŠ¸
"""
from typing import List, Dict, Optional, AsyncGenerator
import httpx
import logging
from ..config import settings

logger = logging.getLogger(__name__)


class OpenRouterClient:
    """
    OpenRouter API í´ë¼ì´ì–¸íŠ¸
    Claude, GPT-4, Llama ë“± ë‹¤ì–‘í•œ ëª¨ë¸ ì§€ì›
    """
    
    def __init__(
        self,
        api_key: Optional[str] = None,
        base_url: str = "https://openrouter.ai/api/v1"
    ):
        """
        Args:
            api_key: OpenRouter API í‚¤ (ì—†ìœ¼ë©´ ì„¤ì •ì—ì„œ ê°€ì ¸ì˜´)
            base_url: OpenRouter API ê¸°ë³¸ URL
        """
        self.api_key = api_key or settings.OPENROUTER_API_KEY
        self.base_url = base_url
        
        if not self.api_key:
            logger.warning("âš ï¸  OpenRouter API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        self.client = httpx.AsyncClient(timeout=60.0)
        
        # ì¶”ì²œ ëª¨ë¸ ëª©ë¡
        self.models = {
            "claude": "anthropic/claude-3.5-sonnet",  # ê³ í’ˆì§ˆ, ë¹ ë¦„
            "gpt4": "openai/gpt-4o",                   # ìµœì‹  GPT-4
            "gpt4-mini": "openai/gpt-4o-mini",         # ê²½ì œì 
            "llama": "meta-llama/llama-3.3-70b-instruct",  # ì˜¤í”ˆì†ŒìŠ¤
            "free": "google/gemini-2.0-flash-exp:free"  # ë¬´ë£Œ (í…ŒìŠ¤íŠ¸ìš©)
        }
    
    async def chat_completion(
        self,
        messages: List[Dict[str, str]],
        model: str = "gpt4-mini",
        temperature: float = 0.7,
        max_tokens: int = 1000,
        stream: bool = False
    ) -> Dict:
        """
        ì±„íŒ… ì™„ì„± API í˜¸ì¶œ
        
        Args:
            messages: ëŒ€í™” ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ [{"role": "user", "content": "..."}]
            model: ëª¨ë¸ ì´ë¦„ (claude, gpt4, gpt4-mini, llama, free)
            temperature: ì°½ì˜ì„± (0.0~1.0)
            max_tokens: ìµœëŒ€ í† í° ìˆ˜
            stream: ìŠ¤íŠ¸ë¦¬ë° ì—¬ë¶€
            
        Returns:
            Dict: API ì‘ë‹µ
        """
        if not self.api_key:
            raise ValueError("OpenRouter API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # ëª¨ë¸ ì´ë¦„ ë§¤í•‘
        model_id = self.models.get(model, model)
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
            "HTTP-Referer": "https://github.com/yourusername/Pawna",  # ì„ íƒ
            "X-Title": "Pawna Chatbot"  # ì„ íƒ
        }
        
        payload = {
            "model": model_id,
            "messages": messages,
            "temperature": temperature,
            "max_tokens": max_tokens,
            "stream": stream
        }
        
        try:
            logger.info(f"ğŸ¤– OpenRouter API í˜¸ì¶œ: {model_id}")
            
            if stream:
                # ìŠ¤íŠ¸ë¦¬ë°ì€ ë³„ë„ ë©”ì„œë“œë¡œ
                return await self._stream_completion(headers, payload)
            else:
                response = await self.client.post(
                    f"{self.base_url}/chat/completions",
                    headers=headers,
                    json=payload
                )
                response.raise_for_status()
                return response.json()
                
        except httpx.HTTPStatusError as e:
            logger.error(f"âŒ OpenRouter API ì˜¤ë¥˜: {e.response.status_code} - {e.response.text}")
            raise
        except Exception as e:
            logger.error(f"âŒ OpenRouter API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            raise
    
    async def _stream_completion(
        self,
        headers: Dict,
        payload: Dict
    ) -> AsyncGenerator[str, None]:
        """
        ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬
        """
        async with self.client.stream(
            "POST",
            f"{self.base_url}/chat/completions",
            headers=headers,
            json=payload
        ) as response:
            response.raise_for_status()
            async for line in response.aiter_lines():
                if line.startswith("data: "):
                    yield line[6:]  # "data: " ì œê±°
    
    def format_messages(
        self,
        system_prompt: str,
        user_message: str,
        context: Optional[str] = None,
        conversation_history: Optional[List[Dict]] = None
    ) -> List[Dict[str, str]]:
        """
        OpenRouter ë©”ì‹œì§€ í˜•ì‹ìœ¼ë¡œ í¬ë§·íŒ…
        
        Args:
            system_prompt: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
            user_message: ì‚¬ìš©ì ë©”ì‹œì§€
            context: RAG ì»¨í…ìŠ¤íŠ¸ (ì„ íƒ)
            conversation_history: ëŒ€í™” íˆìŠ¤í† ë¦¬ (ì„ íƒ)
            
        Returns:
            List[Dict]: OpenRouter ë©”ì‹œì§€ í˜•ì‹
        """
        messages = []
        
        # 1. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        full_system_prompt = system_prompt
        if context:
            full_system_prompt += f"\n\n# ì°¸ê³  ì •ë³´\n{context}"
        
        messages.append({
            "role": "system",
            "content": full_system_prompt
        })
        
        # 2. ëŒ€í™” íˆìŠ¤í† ë¦¬ (ìˆìœ¼ë©´)
        if conversation_history:
            messages.extend(conversation_history[-5:])  # ìµœê·¼ 5ê°œë§Œ
        
        # 3. í˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€
        messages.append({
            "role": "user",
            "content": user_message
        })
        
        return messages
    
    async def close(self):
        """í´ë¼ì´ì–¸íŠ¸ ì¢…ë£Œ"""
        await self.client.aclose()


# ì „ì—­ OpenRouter í´ë¼ì´ì–¸íŠ¸
_openrouter_client: Optional[OpenRouterClient] = None


def get_openrouter_client() -> OpenRouterClient:
    """OpenRouter í´ë¼ì´ì–¸íŠ¸ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _openrouter_client
    if _openrouter_client is None:
        _openrouter_client = OpenRouterClient()
    return _openrouter_client
